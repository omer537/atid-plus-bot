import streamlit as st
import google.generativeai as genai

# --- 专转 祝 ---
st.set_page_config(page_title="注转 + | 注专转 转 砖注专", page_icon="", layout="centered")

# !!! 砖  转 驻转 砖 !!!
GOOGLE_API_KEY = "AIzaSyC_k0wykusqS8mXPwBg4xd2FcZno5S5Ci0"

MAX_QUESTIONS = 5

# --- 专转 拽 (拽转) ---
bot_avatar = ""  # 拽 专拽 
user_avatar = ""  # 拽  专

# --- 注爪 CSS 拽 转 ---
st.markdown("""
<style>
    /* 驻 砖专   祝 */
    html, body, [class*="css"] {
        font-family: 'Segoe UI', Helvetica, Arial, sans-serif;
    }
    .stChatMessage, .stMarkdown, p, div, input, h1, h2, h3, h4 {
        direction: rtl;
        text-align: right;
    }

    /* 注爪 注转 专 (砖转砖) */
    .stChatMessage.user {
        flex-direction: row-reverse;
        background-color: #e3f2fd; /*  专  */
        border-radius: 15px;
        border: 1px solid #bbdefb;
    }

    /* 注爪 注转  (注转+) */
    .stChatMessage.assistant {
        background-color: #f1f8e9; /* 专拽 专 / */
        border-radius: 15px;
        border: 1px solid #dcedc8;
    }

    /* 转专转 转转 */
    .branding-header {
        color: #1a237e; /*   */
        font-weight: bold;
        font-size: 3rem;
        margin-bottom: 0;
        text-align: center;
        text-shadow: 1px 1px 2px #ccc;
    }
    .branding-sub {
        color: #2e7d32; /* 专拽 */
        font-size: 1.3rem;
        text-align: center;
        margin-top: -10px;
        margin-bottom: 30px;
        font-weight: 500;
    }

    /* 住转专转   砖 注专转 */
    .stDeployButton {display:none;}
    header {visibility: hidden;}
    p { margin-bottom: 0.8rem; line-height: 1.6; }
</style>
""", unsafe_allow_html=True)

if GOOGLE_API_KEY != "YOUR_API_KEY_HERE":
    genai.configure(api_key=GOOGLE_API_KEY)
    model_pro = genai.GenerativeModel('gemini-2.5-pro')
    model_flash = genai.GenerativeModel('gemini-2.5-flash')

# --- 专 (Session State) ---
if "stage" not in st.session_state:
    st.session_state.stage = "setup_name"
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": ". 专  注专转 转 砖 注转+.  拽专 ?"}]
if "teacher_data" not in st.session_state:
    st.session_state.teacher_data = {"name": "", "location": "", "topic": "", "preferences": ""}
if "lesson_plan_text" not in st.session_state:
    st.session_state.lesson_plan_text = ""
if "question_count" not in st.session_state:
    st.session_state.question_count = 0

# --- 转  (PROMPTS) ---

LESSON_FORMAT_PROMPT = """
转  驻 砖 专转 "注转 +".
专: 爪专转 注专 砖注专 转 砖转, 注拽 驻专拽.

**转 "注砖  转注砖":**
1. ** 转专转 驻转:**  转转 "砖:...", 转 砖专 转.
2. ** 砖:** 专 转 住专   砖,   转  9 专.

**9 专 :**
1. **注 转:** 住专  砖  驻 住转.
2. **专 爪转:**  专转 转 (/专).
3. **专转:** 住驻专 砖 驻 拽.
4. **专 ( 砖注专):** 转专  专 (驻转 ->  -> 转专).
5. **注 拽:**  专砖 .
6. **爪:** 转专 砖  专 拽转.
7. **拽砖:** 驻 转 驻 (Conceptual Pitfall).
8. **驻转专 拽砖:**  住专 转  .
9. **砖 (驻转):** 驻转 拽 注  砖 .

**转 砖转:**
转 转 注专 砖  砖专 住驻拽 ({preferences}).

**住:**
* Markdown 转专转.
* 砖驻 拽爪注转  注.

 转注 注 砖 10.
"""

SIMULATION_INSTRUCTIONS = f"""
转 注转 爪转 "注转 +" 砖爪注  转 驻.
专:  砖 注专 住专.

**转:**
1. ** 砖:** 住专 砖 砖转 转转 砖转.
2. **拽 驻:** 砖 注 转, 拽砖, 转 砖注专.
3. **转:** {MAX_QUESTIONS} 砖转 住".
4. **住:** 砖转 专拽转 拽爪专转.
"""


def check_user_intent_with_ai(user_text):
    if GOOGLE_API_KEY == "YOUR_API_KEY_HERE":
        return False
    prompt = f"""
    砖转砖  注专 砖注专. 转转: "{user_text}".
      砖专 (专爪 转拽)? 注 "APPROVE".
      拽砖转 转拽/砖? 注 "REVISE".
    """
    try:
        response = model_flash.generate_content(prompt).text
        return "APPROVE" in response.strip().upper()
    except:
        return False


def generate_response(prompt, context="", use_fast_model=False):
    if GOOGLE_API_KEY == "YOUR_API_KEY_HERE":
        return "住专 驻转 API 拽."

    active_model = model_flash if use_fast_model else model_pro

    # 专拽转 注驻转 专 驻专驻
    prefs = st.session_state.teacher_data.get("preferences", "")
    current_prompt = SIMULATION_INSTRUCTIONS if use_fast_model else LESSON_FORMAT_PROMPT.replace("{preferences}", prefs)

    history = [{"role": "user", "parts": [current_prompt]}]
    if context:
        history.append({"role": "user", "parts": [f"住 :\n{context}"]})

    if use_fast_model:
        recent_msgs = st.session_state.messages[-8:]
        for msg in recent_msgs:
            role = "user" if msg["role"] == "user" else "model"
            history.append({"role": role, "parts": [msg["content"]]})

    try:
        response = active_model.generate_content(history + [{"role": "user", "parts": [prompt]}])
        return response.text
    except Exception as e:
        return f"砖: {str(e)}"


# --- UI (砖拽 砖转砖) ---

# 转专转 转转 (拽住 注爪 拽 转)
st.markdown('<div class="branding-header">注转 +</div>', unsafe_allow_html=True)
st.markdown('<div class="branding-sub"> 驻专抓 专</div>', unsafe_allow_html=True)
st.markdown("---")

# 转 注转 注 拽 砖 ( / )
for msg in st.session_state.messages:
    current_avatar = bot_avatar if msg["role"] == "assistant" else user_avatar

    with st.chat_message(msg["role"], avatar=current_avatar):
        st.markdown(msg["content"])

# 拽
if user_input := st.chat_input("拽 ..."):
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("user", avatar=user_avatar):
        st.markdown(user_input)

    response_text = ""

    # --- 拽 ---

    if st.session_state.stage == "setup_name":
        st.session_state.teacher_data["name"] = user_input
        response_text = f" {user_input}, 祝 砖转 转. 驻 转 ?"
        st.session_state.stage = "setup_location"

    elif st.session_state.stage == "setup_location":
        st.session_state.teacher_data["location"] = user_input
        response_text = "注. 注  砖   转 砖注专 ?"
        st.session_state.stage = "setup_topic"

    elif st.session_state.stage == "setup_topic":
        st.session_state.teacher_data["topic"] = user_input
        response_text = "**爪.** 驻 砖  转 注专,  砖  砖 ?\n(砖: 转 转拽砖, 拽爪 拽, 砖 注 拽专...)\n , 驻砖 转 ''."
        st.session_state.stage = "planning"

    elif st.session_state.stage == "planning":
        st.session_state.teacher_data["preferences"] = user_input
        topic = st.session_state.teacher_data["topic"]

        with st.spinner("砖拽 转 砖 砖  注专..."):
            full_request = f"砖: {topic}. 砖 : {user_input}.  转 注专 ."
            ai_response = generate_response(full_request, use_fast_model=False)
            st.session_state.lesson_plan_text = ai_response
            response_text = ai_response + "\n\n---\n** 爪?** 转专爪 砖转拽 砖  砖驻砖专 转拽?"
            st.session_state.stage = "approval"

    elif st.session_state.stage == "approval":
        is_approved = check_user_intent_with_ai(user_input)

        if is_approved:
            st.session_state.stage = "simulation_active"
            st.session_state.question_count = 1
            with st.spinner("住,  注砖 拽 专..."):
                q1 = generate_response(f"转转 转 住爪 驻转. 爪 砖 1 转 {MAX_QUESTIONS}.",
                                       context=st.session_state.lesson_plan_text, use_fast_model=True)
                response_text = f"**拽转 转 驻转 ({MAX_QUESTIONS} 砖转)**\n\n" + q1
        else:
            with st.spinner(" 注, 砖驻专..."):
                ai_response = generate_response(f"注专转 砖转砖: {user_input}. 注专 砖 转 注专.",
                                                context=st.session_state.lesson_plan_text, use_fast_model=False)
                st.session_state.lesson_plan_text = ai_response
                response_text = ai_response + "\n\n** 专住 ?**"

    elif st.session_state.stage == "simulation_active":
        if st.session_state.question_count < MAX_QUESTIONS:
            st.session_state.question_count += 1
            q_num = st.session_state.question_count
            with st.spinner("拽..."):
                response_text = generate_response(f"转砖: '{user_input}'. 砖 拽爪专 砖 驻转 {q_num}.",
                                                  context=st.session_state.lesson_plan_text, use_fast_model=True)
        else:
            with st.spinner("住..."):
                feedback = generate_response(f"转砖 专: '{user_input}'. 住 拽爪专.",
                                             context=st.session_state.lesson_plan_text, use_fast_model=True)
                response_text = feedback + "\n\n**住.**\n砖 专:  注 砖 砖 砖注专 ?"
                st.session_state.stage = "final_question"

    elif st.session_state.stage == "final_question":
        final_doc = st.session_state.lesson_plan_text + f"\n\n**10. 注 砖:**\n{user_input}"
        response_text = "转注 砖  .  爪! "
        st.balloons()
        st.session_state.stage = "finished"

    st.session_state.messages.append({"role": "assistant", "content": response_text})
    with st.chat_message("assistant", avatar=current_avatar):
        st.markdown(response_text)